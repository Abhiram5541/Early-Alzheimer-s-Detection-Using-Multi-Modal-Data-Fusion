import tensorflow as tf
from tensorflow import keras
from keras import layers
from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.metrics import AUC, Precision, Recall
import matplotlib.pyplot as plt
import numpy as np
import os
import shutil
import glob
import pandas as pd
from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns
from PIL import Image
import logging

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# --- Constants ---
# IMPORTANT: Update these paths to match your local data directory structure.
# Your directory should be organized with subfolders for each class (e.g., 'data/MRI/AD', 'data/MRI/CN').
MRI_DATA_DIR = 'C:\\Users\\ABHIRAM\\OneDrive\\Desktop\\alzheimers\\data\\MRI'
CT_DATA_DIR = 'C:\\Users\\ABHIRAM\\OneDrive\\Desktop\\alzheimers\\data\\CT'
OUTPUT_DIR = 'output_multimodal'

IMG_HEIGHT = 224
IMG_WIDTH = 224
BATCH_SIZE = 16  # Smaller batch size for dual inputs
EPOCHS = 100
SEED = 1345
CONFIDENCE_THRESHOLD = 0.85

tf.random.set_seed(SEED)
np.random.seed(SEED)

# --- Data Generators ---
# 1. Training Generator with Data Augmentation
train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest',
    validation_split=0.2 # 80-20 split
)

# 2. Validation Generator (No Augmentation)
val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(
    rescale=1./255,
    validation_split=0.2
)

# --- Flow from Directories (CRITICAL: Set shuffle=False for correct pairing) ---
# MRI Generators
mri_train_ds = train_datagen.flow_from_directory(
    MRI_DATA_DIR,
    target_size=(IMG_HEIGHT, IMG_WIDTH),
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    subset='training',
    shuffle=False,  # IMPORTANT: Maintain consistent order for pairing
    seed=SEED
)
mri_val_ds = val_datagen.flow_from_directory(
    MRI_DATA_DIR,
    target_size=(IMG_HEIGHT, IMG_WIDTH),
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    subset='validation',
    shuffle=False, # IMPORTANT: Maintain consistent order for pairing
    seed=SEED
)

# CT Generators
ct_train_ds = train_datagen.flow_from_directory(
    CT_DATA_DIR,
    target_size=(IMG_HEIGHT, IMG_WIDTH),
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    subset='training',
    shuffle=False, # IMPORTANT: Maintain consistent order for pairing
    seed=SEED
)
ct_val_ds = val_datagen.flow_from_directory(
    CT_DATA_DIR,
    target_size=(IMG_HEIGHT, IMG_WIDTH),
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    subset='validation',
    shuffle=False, # IMPORTANT: Maintain consistent order for pairing
    seed=SEED
)

# Ensure class names are consistent across all generators
class_names = list(mri_train_ds.class_indices.keys())
print("Class Names:", class_names)

# --- Corrected Combined Generator for Multi-Modal Input ---
def combined_generator(ct_gen, mri_gen):
    while True:
        ct_batch = next(ct_gen)
        mri_batch = next(mri_gen)
        # CRITICAL FIX: Change list [] to tuple () for the input data
        yield (ct_batch[0], mri_batch[0]), ct_batch[1]

# --- CORRECTED: Use tf.data.Dataset.from_generator ---
# Wrap the Python generator in a tf.data.Dataset for TensorFlow compatibility
train_ds_combined = tf.data.Dataset.from_generator(
    lambda: combined_generator(ct_train_ds, mri_train_ds),
    output_signature=(
        (
            tf.TensorSpec(shape=(None, IMG_HEIGHT, IMG_WIDTH, 3), dtype=tf.float32),
            tf.TensorSpec(shape=(None, IMG_HEIGHT, IMG_WIDTH, 3), dtype=tf.float32)
        ),
        tf.TensorSpec(shape=(None, len(class_names)), dtype=tf.float32)
    )
).repeat().prefetch(tf.data.AUTOTUNE)

val_ds_combined = tf.data.Dataset.from_generator(
    lambda: combined_generator(ct_val_ds, mri_val_ds),
    output_signature=(
        (
            tf.TensorSpec(shape=(None, IMG_HEIGHT, IMG_WIDTH, 3), dtype=tf.float32),
            tf.TensorSpec(shape=(None, IMG_HEIGHT, IMG_WIDTH, 3), dtype=tf.float32)
        ),
        tf.TensorSpec(shape=(None, len(class_names)), dtype=tf.float32)
    )
).repeat().prefetch(tf.data.AUTOTUNE)

# --- Model: Dual Branch CNN ---
def create_branch(input_shape, name):
    inputs = layers.Input(shape=input_shape, name=name)
    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)
    x = layers.BatchNormalization()(x)
    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)
    x = layers.MaxPooling2D(2, 2)(x)
    x = layers.Dropout(0.25)(x)

    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)
    x = layers.BatchNormalization()(x)
    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)
    x = layers.MaxPooling2D(2, 2)(x)
    x = layers.Dropout(0.25)(x)

    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)
    x = layers.BatchNormalization()(x)
    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)
    x = layers.GlobalAveragePooling2D()(x)

    return inputs, x

# Two separate branches for CT and MRI
ct_input, ct_branch = create_branch((IMG_HEIGHT, IMG_WIDTH, 3), "CT_Input")
mri_input, mri_branch = create_branch((IMG_HEIGHT, IMG_WIDTH, 3), "MRI_Input")

# Merge features
merged = layers.concatenate([ct_branch, mri_branch])
x = layers.Dense(256, activation='relu')(merged)
x = layers.Dropout(0.5)(x)
output = layers.Dense(len(class_names), activation='softmax')(x)

model = keras.Model(inputs=[ct_input, mri_input], outputs=output)

# --- Compile Model ---
initial_learning_rate = 0.001
lr_schedule = keras.optimizers.schedules.ExponentialDecay(
    initial_learning_rate,
    decay_steps=100,
    decay_rate=0.96,
    staircase=True
)

model.compile(
    loss="categorical_crossentropy",
    optimizer=keras.optimizers.Adam(learning_rate=lr_schedule),
    metrics=['accuracy', AUC(name='auc'), Precision(name='precision'), Recall(name='recall')]
)
model.summary()

# --- Callbacks ---
# Update the file name to use the new format
checkpoint_filepath = './multimodal_best_weights.weights.keras'
earlystopping = EarlyStopping(monitor='val_accuracy', mode='max', patience=15, restore_best_weights=True, verbose=1)
checkpoint = ModelCheckpoint(checkpoint_filepath, monitor='val_accuracy', mode='max', save_best_only=True, verbose=1)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-5, verbose=1)

callbacks_list = [earlystopping, checkpoint, reduce_lr]

# --- Training ---
steps_per_epoch = min(len(ct_train_ds), len(mri_train_ds))
validation_steps = min(len(ct_val_ds), len(mri_val_ds))

# --- CORRECTED: Use the new tf.data.Dataset objects in model.fit ---
history = model.fit(
    train_ds_combined,
    steps_per_epoch=steps_per_epoch,
    validation_data=val_ds_combined,
    validation_steps=validation_steps,
    epochs=EPOCHS,
    verbose=1,
    callbacks=callbacks_list
)

# --- Evaluation ---
print("\n--- Evaluating model ---")
model.load_weights(checkpoint_filepath)
loss, acc, auc, precision, recall = model.evaluate(val_ds_combined, steps=validation_steps)
print(f"Validation Loss: {loss:.4f} | Accuracy: {acc:.4f} | AUC: {auc:.4f} | Precision: {precision:.4f} | Recall: {recall:.4f}")

# --- Save Model ---
# This will save your model in the new native Keras format.
model.save('alzheimers_multimodal_model.keras')
print("Model saved as 'alzheimers_multimodal_model.keras'")

# --- Plot Training History ---
def plot_history(history):
    acc = history.history['accuracy']
    val_acc = history.history['val_accuracy']
    loss = history.history['loss']
    val_loss = history.history['val_loss']
    epochs_range = range(len(acc))

    plt.figure(figsize=(12, 6))
    plt.subplot(1, 2, 1)
    plt.plot(epochs_range, acc, label='Training Accuracy')
    plt.plot(epochs_range, val_acc, label='Validation Accuracy')
    plt.legend(loc='lower right')
    plt.title('Training and Validation Accuracy')

    plt.subplot(1, 2, 2)
    plt.plot(epochs_range, loss, label='Training Loss')
    plt.plot(epochs_range, val_loss, label='Validation Loss')
    plt.legend(loc='upper right')
    plt.title('Training and Validation Loss')
    plt.show()

plot_history(history)

# --- Generate and Plot Confusion Matrix ---
print("\n--- Generating Confusion Matrix ---")
# Reset the validation generator to get true labels in correct order
mri_val_ds.reset()
ct_val_ds.reset()
val_gen_for_pred = combined_generator(ct_val_ds, mri_val_ds)

# Get predictions and true labels
predictions = model.predict(val_ds_combined, steps=validation_steps)
y_pred = np.argmax(predictions, axis=1)
y_true = mri_val_ds.classes[:validation_steps * BATCH_SIZE] # Ensure labels match the number of predictions

cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)
plt.title('Confusion Matrix')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

print("\n--- Classification Report ---")
print(classification_report(y_true, y_pred, target_names=class_names))

# --- Prediction for Single MRI + CT Pair ---
from tensorflow.keras.preprocessing import image

def load_and_preprocess_img(path):
    img = image.load_img(path, target_size=(IMG_HEIGHT, IMG_WIDTH))
    img_array = image.img_to_array(img) / 255.0
    return np.expand_dims(img_array, axis=0)

def predict_pair(ct_path, mri_path):
    ct_img = load_and_preprocess_img(ct_path)
    mri_img = load_and_preprocess_img(mri_path)
    pred = model.predict([ct_img, mri_img])
    predicted_class = class_names[np.argmax(pred)]
    confidence = np.max(pred)
    print(f"Predicted Class: {predicted_class} | Confidence: {confidence*100:.2f}%")
    return predicted_class, confidence

# Example Usage
ct_example = "sample_ct.jpg"
mri_example = "sample_mri.jpg"
if os.path.exists(ct_example) and os.path.exists(mri_example):
    predict_pair(ct_example, mri_example)
else:
    print("Sample images not found. Please provide valid paths.")
